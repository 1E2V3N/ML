{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d5c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96794232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probabilities = {}\n",
    "        self.feature_probabilities = {}\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # Calculate class probabilities\n",
    "        self.calculate_class_probabilities(y_train)\n",
    "        \n",
    "        # Calculate feature probabilities for each class\n",
    "        self.calculate_feature_probabilities(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for sample in X_test:\n",
    "            prediction = self.predict_sample(sample)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_sample(self, sample):\n",
    "        best_class = None\n",
    "        best_probability = -1\n",
    "        \n",
    "        for class_label, class_probability in self.class_probabilities.items():\n",
    "            feature_probabilities = self.feature_probabilities[class_label]\n",
    "            probability = class_probability\n",
    "            \n",
    "            for i in range(len(sample)):\n",
    "                feature_value = sample[i]\n",
    "                if feature_value in feature_probabilities[i]:\n",
    "                    probability *= feature_probabilities[i][feature_value]\n",
    "            \n",
    "            if probability > best_probability:\n",
    "                best_class = class_label\n",
    "                best_probability = probability\n",
    "        \n",
    "        return best_class\n",
    "    \n",
    "    def calculate_class_probabilities(self, y_train):\n",
    "        total_samples = len(y_train)\n",
    "        class_counts = {}\n",
    "        \n",
    "        for class_label in y_train:\n",
    "            if class_label in class_counts:\n",
    "                class_counts[class_label] += 1\n",
    "            else:\n",
    "                class_counts[class_label] = 1\n",
    "        \n",
    "        for class_label, count in class_counts.items():\n",
    "            self.class_probabilities[class_label] = count / total_samples\n",
    "    \n",
    "    def calculate_feature_probabilities(self, X_train, y_train):\n",
    "        num_features = len(X_train[0])\n",
    "        class_counts = {}\n",
    "        self.feature_probabilities = {}\n",
    "        \n",
    "        for i in range(len(X_train)):\n",
    "            sample = X_train[i]\n",
    "            class_label = y_train[i]\n",
    "            \n",
    "            if class_label not in class_counts:\n",
    "                class_counts[class_label] = 1\n",
    "                self.feature_probabilities[class_label] = [{} for _ in range(num_features)]\n",
    "            else:\n",
    "                class_counts[class_label] += 1\n",
    "            \n",
    "            feature_probabilities = self.feature_probabilities[class_label]\n",
    "            \n",
    "            for j in range(num_features):\n",
    "                feature_value = sample[j]\n",
    "                if feature_value in feature_probabilities[j]:\n",
    "                    feature_probabilities[j][feature_value] += 1\n",
    "                else:\n",
    "                    feature_probabilities[j][feature_value] = 1\n",
    "        \n",
    "        for class_label, count in class_counts.items():\n",
    "            feature_probabilities = self.feature_probabilities[class_label]\n",
    "            for j in range(num_features):\n",
    "                total_count = count + len(feature_probabilities[j])\n",
    "                for feature_value in feature_probabilities[j]:\n",
    "                    feature_probabilities[j][feature_value] /= total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "703ff202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Salary_Data.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e038f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features (X) and target variable (y) for classification\n",
    "salary_threshold = data_encoded[\"Salary\"].mean()\n",
    "data_encoded[\"Salary_Class\"] = np.where(data_encoded[\"Salary\"] >= salary_threshold, \"High\", \"Low\")\n",
    "X_cls = data_encoded.drop([\"Salary\", \"Salary_Class\"], axis=1)\n",
    "y_cls = data_encoded[\"Salary_Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1b6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical labels\n",
    "X_nb = X_cls.values\n",
    "label_encoders = {}\n",
    "for col in range(X_nb.shape[1]):\n",
    "    unique_values = np.unique(X_nb[:, col])\n",
    "    label_encoders[col] = {value: i for i, value in enumerate(unique_values)}\n",
    "    X_nb[:, col] = np.array([label_encoders[col][value] for value in X_nb[:, col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c181003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "X_nb_train, X_nb_test, y_nb_train, y_nb_test = train_test_split(X_nb, y_cls.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6193d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Naive Bayes classifier\n",
    "nb_model = NaiveBayesClassifier()\n",
    "nb_model.fit(X_nb_train, y_nb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca7d373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "nb_predictions = nb_model.predict(X_nb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9166f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7104477611940299\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = np.mean(nb_predictions == y_nb_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
